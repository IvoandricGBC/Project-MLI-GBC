{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1osQnQkIXf0zgjjwpFj8Ett8_eEoI2Lsx",
      "authorship_tag": "ABX9TyPzyB5lrP6G+gWgZTcXJkTo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvoandricGBC/Project-MLI-GBC/blob/main/distance_estimation_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkJtossEWr6j",
        "outputId": "1c34b983-b780-4af9-de9f-cabcbc03f941"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO B: CARGA, CONFIGURACIÓN Y SPLIT ───\n",
        "\n",
        "\n",
        "# 1. Semilla global para reproducibilidad\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# 2. Definición de rutas\n",
        "env_name = 'distance_estimation'\n",
        "base_dir  = f\"/content/drive/MyDrive/Colab Notebooks/{env_name}\"\n",
        "csv_path  = os.path.join(base_dir, 'labels.csv')\n",
        "img_dir   = os.path.join(base_dir, 'images')\n",
        "\n",
        "# 3. Carga de datos de metadatos\n",
        "df = pd.read_csv(csv_path)\n",
        "# Forzamos que ID sea string para todo el pipeline\n",
        "df['ID'] = df['ID'].astype(str)\n",
        "\n",
        "assert 'class' in df.columns, \"Falta la columna 'class' en labels.csv\"\n",
        "\n",
        "# 4. Split estratificado en train/val\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=SEED,\n",
        "    stratify=df['class']  # conserva proporción de clases\n",
        ")\n",
        "\n",
        "# 5. Feedback por consola\n",
        "print(f\"Train shape: {train_df.shape}, Val shape: {val_df.shape}\")\n",
        "print(\"Distribución de clases en train:\\n\", train_df['class'].value_counts(normalize=True))\n",
        "print(\"Distribución de clases en val:\\n\",   val_df  ['class'].value_counts(normalize=True))\n",
        "\n",
        "# 6. Opcional: inspección rápida de algunas rutas\n",
        "print(f\"Ejemplo de imagen disponible en: {os.path.join(img_dir, train_df.iloc[0]['ID'] + '.png')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG6zxh_cWy8b",
        "outputId": "bdd1f4ca-1d38-4178-e4b8-d0b2063a89dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (400, 6), Val shape: (100, 6)\n",
            "Distribución de clases en train:\n",
            " class\n",
            "1    0.5275\n",
            "0    0.4725\n",
            "Name: proportion, dtype: float64\n",
            "Distribución de clases en val:\n",
            " class\n",
            "1    0.53\n",
            "0    0.47\n",
            "Name: proportion, dtype: float64\n",
            "Ejemplo de imagen disponible en: /content/drive/MyDrive/Colab Notebooks/distance_estimation/images/164.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO C: DATASET Y TRANSFORMACIONES ───\n",
        "\n",
        "# ─── MÓDULO C: DATASET Y TRANSFORMACIONES ───\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 1. Columnas de metadata\n",
        "metadata_cols = ['Width', 'location']\n",
        "\n",
        "# 2. Escalado de metadatos (solo sobre train ¡IMPORTANTE!)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajuste y transformación en train\n",
        "scaled_train = scaler.fit_transform(train_df[metadata_cols].astype(float))\n",
        "train_df[metadata_cols] = pd.DataFrame(\n",
        "    scaled_train,\n",
        "    columns=metadata_cols,\n",
        "    index=train_df.index\n",
        ")\n",
        "\n",
        "# Transformación en val\n",
        "scaled_val = scaler.transform(val_df[metadata_cols].astype(float))\n",
        "val_df[metadata_cols] = pd.DataFrame(\n",
        "    scaled_val,\n",
        "    columns=metadata_cols,\n",
        "    index=val_df.index\n",
        ")\n",
        "\n",
        "# 3. Normalización del label (min-max) basada en train_df\n",
        "min_l, max_l = train_df['label'].min(), train_df['label'].max()\n",
        "train_df['label_norm'] = (train_df['label'] - min_l) / (max_l - min_l)\n",
        "val_df['label_norm']   = (val_df['label']   - min_l) / (max_l - min_l)\n",
        "\n",
        "# 4. Transformaciones de imagen\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "# 5. Dataset personalizado\n",
        "class DistanceDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, f\"{row['ID']}.png\")\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        meta_vals = row[metadata_cols].values.astype(np.float32)\n",
        "        meta = torch.from_numpy(meta_vals)\n",
        "        label = torch.tensor(row['label_norm'], dtype=torch.float32)\n",
        "        return img, meta, label\n",
        "\n",
        "# 6. DataLoaders\n",
        "batch_size = 32\n",
        "train_ds = DistanceDataset(train_df, img_dir, transform=train_transforms)\n",
        "val_ds   = DistanceDataset(val_df,   img_dir, transform=val_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "print(f\"[+] DataLoaders OK — {len(train_ds)} imgs en train, {len(val_ds)} en val\")\n"
      ],
      "metadata": {
        "id": "DaUqoC6pW-Wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9401c220-0045-416f-a907-4a651d1bd231"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] DataLoaders OK — 400 imgs en train, 100 en val\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO D: DATALOADERS AVANZADOS ───\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Parámetros comunes\n",
        "batch_size = 32      # o ajústalo según tu memoria disponible\n",
        "num_workers = 4      # idealmente = número de CPUs disponibles\n",
        "prefetch_factor = 2  # cuántos batches prefetch por worker\n",
        "drop_last = True     # para mantener consistencia de tamaño de batch\n",
        "\n",
        "# Generador para reproducibilidad en el shuffle\n",
        "g = torch.Generator()\n",
        "g.manual_seed(SEED)\n",
        "\n",
        "# 1. Train loader con shuffling reproducible\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=prefetch_factor,\n",
        "    drop_last=drop_last,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "# 2. Val loader sin shuffle\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=prefetch_factor,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# 3. (Opcional) Sampler ponderado si hubiera desbalance\n",
        "# from torch.utils.data import WeightedRandomSampler\n",
        "# class_counts = train_df['class'].value_counts().to_dict()\n",
        "# weights = [1.0 / class_counts[c] for c in train_df['class']]\n",
        "# sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "# train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, ...)\n",
        "\n",
        "print(f\"[+] Train loader: {len(train_loader)} batches, Val loader: {len(val_loader)} batches\")\n"
      ],
      "metadata": {
        "id": "sl0pge74XbOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2877ff60-44be-4d75-8190-7d8ce66d8920"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Train loader: 12 batches, Val loader: 4 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO E: ARQUITECTURA DEL MODELO ───\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "class DistanceModel(nn.Module):\n",
        "    def __init__(self, num_meta_feat, head_sizes=[256, 128], backbone_name='resnet50', pretrained=True):\n",
        "        super().__init__()\n",
        "        # 1. Backbone CNN\n",
        "        if backbone_name == 'resnet50':\n",
        "            self.backbone = models.resnet50(pretrained=pretrained)\n",
        "        elif backbone_name == 'resnet34':\n",
        "            self.backbone = models.resnet34(pretrained=pretrained)\n",
        "        else:\n",
        "            raise ValueError(f\"Backbone {backbone_name} no soportado\")\n",
        "\n",
        "        # 2. Congelar todas las capas excepto layer4 (freezing progresivo)\n",
        "        for name, param in self.backbone.named_parameters():\n",
        "            param.requires_grad = False\n",
        "            if 'layer4' in name:\n",
        "                param.requires_grad = True\n",
        "\n",
        "        # 3. Sustituir la cabeza final de la CNN\n",
        "        cnn_feats = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()   # deja pasar los features puros\n",
        "\n",
        "        # 4. MLP para metadata\n",
        "        self.meta_net = nn.Sequential(\n",
        "            nn.Linear(num_meta_feat, head_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(head_sizes[0], head_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "        # 5. Cabeza combinada (imagen + metadata)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(cnn_feats + head_sizes[1], 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1)  # salida regresión\n",
        "        )\n",
        "\n",
        "    def forward(self, img, meta):\n",
        "        # Extraer features de la imagen\n",
        "        x_img = self.backbone(img)           # [batch, cnn_feats]\n",
        "        # Procesar metadata\n",
        "        x_meta = self.meta_net(meta)         # [batch, head_sizes[1]]\n",
        "        # Concatenar\n",
        "        x = torch.cat([x_img, x_meta], dim=1)\n",
        "        # Cabeza final\n",
        "        return self.head(x)\n",
        "\n",
        "# ─ Instanciación ─\n",
        "num_meta = len(metadata_cols)  # p.ej. ['Width','location'] → 2\n",
        "model = DistanceModel(num_meta_feat=num_meta, backbone_name='resnet50').to(device)\n",
        "\n",
        "# ─── MÓDULO E: ARQUITECTURA DEL MODELO ───\n",
        "# (todo lo que ya tienes, incluida la clase DistanceModel y la instanciación)\n",
        "model = DistanceModel(num_meta_feat=num_meta, backbone_name='resnet50').to(device)\n",
        "\n",
        "# ─── Configuración del optimizador con LRs diferenciados ───\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    # 1) Ajuste fino suave de layer4 (backbone)\n",
        "    {'params': model.backbone.layer4.parameters(), 'lr': 1e-4},\n",
        "    # 2) Aprendizaje más rápido de la MLP de metadata\n",
        "    {'params': model.meta_net.parameters(),           'lr': 1e-3},\n",
        "    # 3) Cabeza combinada imagen+metadata\n",
        "    {'params': model.head.parameters(),               'lr': 1e-3},\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWs2a_a0XhLj",
        "outputId": "7002b8de-5f97-452b-bbae-70e9c9187acf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO F: BUCLE DE ENTRENAMIENTO CON MIXED PRECISION (torch.amp) Y EARLY STOPPING ───\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Configuración básica\n",
        "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device_str  = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "loss_fn      = nn.MSELoss()\n",
        "scaler      = GradScaler(device_str)\n",
        "num_epochs   = 50\n",
        "patience     = 5\n",
        "best_val_loss = float('inf')\n",
        "stale_epochs  = 0\n",
        "\n",
        "# 2. Loop de epochs\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # ––– Entrenamiento –––\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for imgs, metas, labels in train_loader:\n",
        "        imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_str):\n",
        "            preds = model(imgs, metas).squeeze(1)\n",
        "            loss  = loss_fn(preds, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    train_loss = np.mean(train_losses)\n",
        "\n",
        "    # ––– Validación –––\n",
        "    model.eval()\n",
        "    val_losses  = []\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, metas, labels in val_loader:\n",
        "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "            with autocast(device_str):\n",
        "                preds = model(imgs, metas).squeeze(1)\n",
        "                loss  = loss_fn(preds, labels)\n",
        "            val_losses.append(loss.item())\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    val_loss = np.mean(val_losses)\n",
        "    y_pred   = torch.cat(all_preds).numpy()\n",
        "    y_true   = torch.cat(all_labels).numpy()\n",
        "    val_mae  = mean_absolute_error(y_true, y_pred)\n",
        "    val_r2   = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} | \"\n",
        "        f\"Val Loss:   {val_loss:.4f} | \"\n",
        "        f\"Val MAE:    {val_mae:.4f} | \"\n",
        "        f\"Val R²:     {val_r2:.4f}\"\n",
        "    )\n",
        "\n",
        "    # ––– Early Stopping y checkpoint –––\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        stale_epochs  = 0\n",
        "        torch.save({\n",
        "            'epoch':        epoch,\n",
        "            'model_state':  model.state_dict(),\n",
        "            'opt_state':    optimizer.state_dict(),\n",
        "            'scaler_state': scaler.state_dict()\n",
        "        }, 'best_checkpoint.pt')\n",
        "        print(\"  → Mejor modelo guardado\")\n",
        "    else:\n",
        "        stale_epochs += 1\n",
        "        if stale_epochs >= patience:\n",
        "            print(f\"Stopping early! No mejora en {patience} epochs.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffXpfIy9XpUp",
        "outputId": "d3cab45f-f9ca-48b2-9431-45de08b97852"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 0.3705 | Val Loss:   0.0407 | Val MAE:    0.1631 | Val R²:     0.3242\n",
            "  → Mejor modelo guardado\n",
            "Epoch 02 | Train Loss: 0.0747 | Val Loss:   0.0951 | Val MAE:    0.2661 | Val R²:     -0.6762\n",
            "Epoch 03 | Train Loss: 0.0621 | Val Loss:   0.0247 | Val MAE:    0.1415 | Val R²:     0.5064\n",
            "  → Mejor modelo guardado\n",
            "Epoch 04 | Train Loss: 0.0394 | Val Loss:   0.0180 | Val MAE:    0.1158 | Val R²:     0.6347\n",
            "  → Mejor modelo guardado\n",
            "Epoch 05 | Train Loss: 0.0369 | Val Loss:   0.0257 | Val MAE:    0.1392 | Val R²:     0.4899\n",
            "Epoch 06 | Train Loss: 0.0310 | Val Loss:   0.0129 | Val MAE:    0.0974 | Val R²:     0.7414\n",
            "  → Mejor modelo guardado\n",
            "Epoch 07 | Train Loss: 0.0298 | Val Loss:   0.0143 | Val MAE:    0.0875 | Val R²:     0.7878\n",
            "Epoch 08 | Train Loss: 0.0295 | Val Loss:   0.0096 | Val MAE:    0.0778 | Val R²:     0.8350\n",
            "  → Mejor modelo guardado\n",
            "Epoch 09 | Train Loss: 0.0278 | Val Loss:   0.0100 | Val MAE:    0.0825 | Val R²:     0.8217\n",
            "Epoch 10 | Train Loss: 0.0258 | Val Loss:   0.0055 | Val MAE:    0.0595 | Val R²:     0.9040\n",
            "  → Mejor modelo guardado\n",
            "Epoch 11 | Train Loss: 0.0230 | Val Loss:   0.0083 | Val MAE:    0.0713 | Val R²:     0.8602\n",
            "Epoch 12 | Train Loss: 0.0263 | Val Loss:   0.0163 | Val MAE:    0.1105 | Val R²:     0.7158\n",
            "Epoch 13 | Train Loss: 0.0250 | Val Loss:   0.0059 | Val MAE:    0.0583 | Val R²:     0.9017\n",
            "Epoch 14 | Train Loss: 0.0216 | Val Loss:   0.0108 | Val MAE:    0.0741 | Val R²:     0.8408\n",
            "Epoch 15 | Train Loss: 0.0211 | Val Loss:   0.0164 | Val MAE:    0.0973 | Val R²:     0.7470\n",
            "Stopping early! No mejora en 5 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO G.1 (versión con validación) ───\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast\n",
        "\n",
        "# 1. Restaurar checkpoint\n",
        "ckpt = torch.load('best_checkpoint.pt', map_location=device)\n",
        "model.load_state_dict(ckpt['model_state'])\n",
        "optimizer.load_state_dict(ckpt['opt_state'])\n",
        "scaler.load_state_dict(ckpt['scaler_state'])\n",
        "\n",
        "# 2. Descongelar layer3 + layer4\n",
        "for name, param in model.backbone.named_parameters():\n",
        "    if 'layer3' in name or 'layer4' in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# 3. Reconfigurar optimizador\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.backbone.layer3.parameters(), 'lr': 5e-5},\n",
        "    {'params': model.backbone.layer4.parameters(), 'lr': 1e-4},\n",
        "    {'params': model.meta_net.parameters(),           'lr': 1e-3},\n",
        "    {'params': model.head.parameters(),               'lr': 1e-3},\n",
        "])\n",
        "\n",
        "# 4. Fine-tuning con validación\n",
        "fine_epochs = 10\n",
        "for epoch in range(1, fine_epochs + 1):\n",
        "    # --- Entrenamiento ---\n",
        "    model.train()\n",
        "    for imgs, metas, labels in train_loader:\n",
        "        imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_str):\n",
        "            loss = loss_fn(model(imgs, metas).squeeze(1), labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    # --- Validación ---\n",
        "    model.eval()\n",
        "    val_losses, all_preds, all_labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, metas, labels in val_loader:\n",
        "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "            with autocast(device_str):\n",
        "                preds = model(imgs, metas).squeeze(1)\n",
        "                val_losses.append(loss_fn(preds, labels).item())\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "    val_loss = sum(val_losses) / len(val_losses)\n",
        "    y_pred   = torch.cat(all_preds).numpy()\n",
        "    y_true   = torch.cat(all_labels).numpy()\n",
        "    val_mae  = mean_absolute_error(y_true, y_pred)\n",
        "    val_r2   = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(\n",
        "        f\"[Fine-Tuning] Epoch {epoch:02d} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} | \"\n",
        "        f\"Val MAE:  {val_mae:.4f} | \"\n",
        "        f\"Val R²:   {val_r2:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"→ Fine-tuning de layer3+4 completado\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV2RF45o3m6K",
        "outputId": "79e249e3-3afa-4db8-c61b-e8c95cfbe8f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-Tuning] Epoch 01 | Val Loss: 0.0216 | Val MAE:  0.1277 | Val R²:   0.5863\n",
            "[Fine-Tuning] Epoch 02 | Val Loss: 0.0099 | Val MAE:  0.0841 | Val R²:   0.8126\n",
            "[Fine-Tuning] Epoch 03 | Val Loss: 0.0173 | Val MAE:  0.1073 | Val R²:   0.7165\n",
            "[Fine-Tuning] Epoch 04 | Val Loss: 0.0116 | Val MAE:  0.0806 | Val R²:   0.8134\n",
            "[Fine-Tuning] Epoch 05 | Val Loss: 0.0114 | Val MAE:  0.0850 | Val R²:   0.8109\n",
            "[Fine-Tuning] Epoch 06 | Val Loss: 0.0041 | Val MAE:  0.0559 | Val R²:   0.9198\n",
            "[Fine-Tuning] Epoch 07 | Val Loss: 0.0044 | Val MAE:  0.0568 | Val R²:   0.9065\n",
            "[Fine-Tuning] Epoch 08 | Val Loss: 0.0068 | Val MAE:  0.0707 | Val R²:   0.8597\n",
            "[Fine-Tuning] Epoch 09 | Val Loss: 0.0025 | Val MAE:  0.0422 | Val R²:   0.9494\n",
            "[Fine-Tuning] Epoch 10 | Val Loss: 0.0187 | Val MAE:  0.1196 | Val R²:   0.6908\n",
            "→ Fine-tuning de layer3+4 completado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install optuna\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8iLCmIH6ufh",
        "outputId": "e58eff05-552b-4b53-a145-f14549a3a2a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO G.2: BÚSQUEDA DE HYPERPARÁMETROS CON OPTUNA ───\n",
        "\n",
        "import optuna\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 1. Función objetivo\n",
        "def objective(trial):\n",
        "    # Hiparams a explorar\n",
        "    lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
        "    lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
        "    lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
        "    head1    = trial.suggest_categorical('head1',    [128, 256, 512])\n",
        "    head2    = trial.suggest_categorical('head2',    [64, 128, 256])\n",
        "    drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
        "\n",
        "    # Reconstruir modelo\n",
        "    model = DistanceModel(\n",
        "        num_meta_feat=num_meta,\n",
        "        head_sizes=[head1, head2],\n",
        "        backbone_name='resnet50'\n",
        "    ).to(device)\n",
        "    # Ajustar dropout dinámico\n",
        "    for m in model.meta_net:\n",
        "        if isinstance(m, nn.Dropout):\n",
        "            m.p = drop_p\n",
        "    for m in model.head:\n",
        "        if isinstance(m, nn.Dropout):\n",
        "            m.p = drop_p\n",
        "\n",
        "    # Congelar todo menos layer3+4 inicialmente\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        param.requires_grad = False\n",
        "        if 'layer3' in name or 'layer4' in name:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    # Optimizador con tasas diferenciadas\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.backbone.layer3.parameters(), 'lr': lr_back3},\n",
        "        {'params': model.backbone.layer4.parameters(), 'lr': lr_back4},\n",
        "        {'params': model.meta_net.parameters(),           'lr': lr_meta},\n",
        "        {'params': model.head.parameters(),               'lr': lr_meta},\n",
        "    ])\n",
        "    scaler = GradScaler(device_str)\n",
        "\n",
        "    # Entrenar 3 epochs rápidos\n",
        "    model.train()\n",
        "    for _ in range(3):\n",
        "        for imgs, metas, labels in train_loader:\n",
        "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with autocast(device_str):\n",
        "                preds = model(imgs, metas).squeeze(1)\n",
        "                loss  = nn.MSELoss()(preds, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "    # Validación MAE\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, metas, labels in val_loader:\n",
        "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "            preds = model(imgs, metas).squeeze(1)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "    y_pred = torch.cat(all_preds).numpy()\n",
        "    y_true = torch.cat(all_labels).numpy()\n",
        "    val_mae = mean_absolute_error(y_true, y_pred)\n",
        "    return val_mae\n",
        "\n",
        "# 2. Lanzar estudio\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"▶️ Mejores parámetros:\", study.best_params)\n",
        "print(\"▶️ Mejor MAE:\",      study.best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mTEwFad6ltg",
        "outputId": "0f4abc44-b198-46e6-ca98-8d0a5f86fc89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-26 00:08:09,149] A new study created in memory with name: no-name-23562622-1404-4763-9133-4fcadfeff2e8\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:08:45,811] Trial 0 finished with value: 0.11539826542139053 and parameters: {'lr_back3': 6.0065421300166427e-05, 'lr_back4': 3.3888842173306026e-05, 'lr_meta': 0.0007559804790585012, 'head1': 512, 'head2': 64, 'dropout': 0.1413421392107634}. Best is trial 0 with value: 0.11539826542139053.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:09:05,679] Trial 1 finished with value: 0.14836673438549042 and parameters: {'lr_back3': 4.4861489152315586e-05, 'lr_back4': 1.271143052625495e-05, 'lr_meta': 0.00029173920599564313, 'head1': 128, 'head2': 256, 'dropout': 0.3242566630291823}. Best is trial 0 with value: 0.11539826542139053.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:09:24,805] Trial 2 finished with value: 0.21622569859027863 and parameters: {'lr_back3': 9.042565274302577e-05, 'lr_back4': 2.5353013312183163e-05, 'lr_meta': 0.005542170915286456, 'head1': 128, 'head2': 256, 'dropout': 0.2812865454103828}. Best is trial 0 with value: 0.11539826542139053.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:09:43,511] Trial 3 finished with value: 0.1922038495540619 and parameters: {'lr_back3': 1.4008100445100658e-05, 'lr_back4': 2.69701021438055e-05, 'lr_meta': 0.004708095301058991, 'head1': 128, 'head2': 256, 'dropout': 0.1221422935079462}. Best is trial 0 with value: 0.11539826542139053.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:10:05,742] Trial 4 finished with value: 0.45150643587112427 and parameters: {'lr_back3': 1.0089865640696657e-05, 'lr_back4': 1.5081092819852824e-05, 'lr_meta': 0.007257336122727286, 'head1': 512, 'head2': 128, 'dropout': 0.4627116357977551}. Best is trial 0 with value: 0.11539826542139053.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:10:25,909] Trial 5 finished with value: 0.09591416269540787 and parameters: {'lr_back3': 7.545755970739325e-05, 'lr_back4': 8.316847697471282e-05, 'lr_meta': 0.0001617135712157247, 'head1': 128, 'head2': 128, 'dropout': 0.2842450359668954}. Best is trial 5 with value: 0.09591416269540787.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:10:46,727] Trial 6 finished with value: 0.20672281086444855 and parameters: {'lr_back3': 2.0245823439815754e-05, 'lr_back4': 2.4778682994060067e-05, 'lr_meta': 0.00025627158544761945, 'head1': 512, 'head2': 64, 'dropout': 0.43278645921304937}. Best is trial 5 with value: 0.09591416269540787.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:11:05,732] Trial 7 finished with value: 0.10003410279750824 and parameters: {'lr_back3': 2.4905681982456543e-05, 'lr_back4': 4.352030714766228e-05, 'lr_meta': 0.0003264273995438562, 'head1': 256, 'head2': 256, 'dropout': 0.11848183526082612}. Best is trial 5 with value: 0.09591416269540787.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:11:24,811] Trial 8 finished with value: 0.14833670854568481 and parameters: {'lr_back3': 2.568836564977954e-05, 'lr_back4': 1.3431446521669212e-05, 'lr_meta': 0.0010336386302924533, 'head1': 128, 'head2': 64, 'dropout': 0.19360618674996646}. Best is trial 5 with value: 0.09591416269540787.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:11:45,243] Trial 9 finished with value: 0.09049995243549347 and parameters: {'lr_back3': 6.822738774562765e-05, 'lr_back4': 9.281507543165217e-05, 'lr_meta': 0.0003638578273930553, 'head1': 128, 'head2': 64, 'dropout': 0.20794520933964888}. Best is trial 9 with value: 0.09049995243549347.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:12:04,303] Trial 10 finished with value: 0.21372313797473907 and parameters: {'lr_back3': 4.074096229918674e-05, 'lr_back4': 8.215927089801214e-05, 'lr_meta': 0.001441610394875516, 'head1': 256, 'head2': 64, 'dropout': 0.21992156937476487}. Best is trial 9 with value: 0.09049995243549347.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:12:24,911] Trial 11 finished with value: 0.07563810795545578 and parameters: {'lr_back3': 9.640041646656855e-05, 'lr_back4': 9.688376738562348e-05, 'lr_meta': 0.00010528597139765888, 'head1': 128, 'head2': 128, 'dropout': 0.33870518188826954}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:12:43,681] Trial 12 finished with value: 0.09797856956720352 and parameters: {'lr_back3': 9.196908047499395e-05, 'lr_back4': 9.868483946520208e-05, 'lr_meta': 0.00010299415283989583, 'head1': 128, 'head2': 128, 'dropout': 0.3721577037886386}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:13:02,403] Trial 13 finished with value: 0.10484359413385391 and parameters: {'lr_back3': 5.564989126339384e-05, 'lr_back4': 5.820213998596808e-05, 'lr_meta': 0.0005172542896220024, 'head1': 128, 'head2': 128, 'dropout': 0.22297453959570623}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:13:22,873] Trial 14 finished with value: 0.0804203674197197 and parameters: {'lr_back3': 6.654725448834916e-05, 'lr_back4': 5.915311102897957e-05, 'lr_meta': 0.00011844485666818074, 'head1': 128, 'head2': 64, 'dropout': 0.389983857649854}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:13:41,888] Trial 15 finished with value: 0.24097919464111328 and parameters: {'lr_back3': 9.831627953489221e-05, 'lr_back4': 5.891307370150726e-05, 'lr_meta': 0.0019636409220886736, 'head1': 256, 'head2': 128, 'dropout': 0.39995472313999253}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:14:01,374] Trial 16 finished with value: 0.14085502922534943 and parameters: {'lr_back3': 4.175641380824158e-05, 'lr_back4': 5.9753282462854866e-05, 'lr_meta': 0.00011760048850905471, 'head1': 128, 'head2': 64, 'dropout': 0.33790412092680017}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:14:20,672] Trial 17 finished with value: 0.09052625298500061 and parameters: {'lr_back3': 5.732534888915954e-05, 'lr_back4': 4.214199437909486e-05, 'lr_meta': 0.00017818607665313316, 'head1': 128, 'head2': 128, 'dropout': 0.3830574276644361}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:14:39,631] Trial 18 finished with value: 0.28347551822662354 and parameters: {'lr_back3': 7.52658677988355e-05, 'lr_back4': 6.950859679347002e-05, 'lr_meta': 0.002719434451857791, 'head1': 512, 'head2': 128, 'dropout': 0.4417304347971171}. Best is trial 11 with value: 0.07563810795545578.\n",
            "<ipython-input-10-11e71c820742>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back3 = trial.suggest_loguniform('lr_back3', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_back4 = trial.suggest_loguniform('lr_back4', 1e-5, 1e-4)\n",
            "<ipython-input-10-11e71c820742>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr_meta  = trial.suggest_loguniform('lr_meta',  1e-4, 1e-2)\n",
            "<ipython-input-10-11e71c820742>:16: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  drop_p   = trial.suggest_uniform('dropout',      0.1, 0.5)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[I 2025-05-26 00:14:59,993] Trial 19 finished with value: 0.1390099972486496 and parameters: {'lr_back3': 3.3170596681971894e-05, 'lr_back4': 3.935876433490502e-05, 'lr_meta': 0.00016731640381421916, 'head1': 256, 'head2': 64, 'dropout': 0.490001947756919}. Best is trial 11 with value: 0.07563810795545578.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Mejores parámetros: {'lr_back3': 9.640041646656855e-05, 'lr_back4': 9.688376738562348e-05, 'lr_meta': 0.00010528597139765888, 'head1': 128, 'head2': 128, 'dropout': 0.33870518188826954}\n",
            "▶️ Mejor MAE: 0.07563810795545578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MÓDULO H: ENTRENAMIENTO FINAL CON BEST_PARAMS ───\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# 1. Extraer mejores hiperparámetros\n",
        "bp = study.best_params\n",
        "lr_back3 = bp['lr_back3']\n",
        "lr_back4 = bp['lr_back4']\n",
        "lr_meta  = bp['lr_meta']\n",
        "head1    = bp['head1']\n",
        "head2    = bp['head2']\n",
        "drop_p   = bp['dropout']\n",
        "\n",
        "# 2. Reconstruir modelo con best head sizes y dropout\n",
        "model = DistanceModel(\n",
        "    num_meta_feat=num_meta,\n",
        "    head_sizes=[head1, head2],\n",
        "    backbone_name='resnet50'\n",
        ").to(device)\n",
        "\n",
        "# Ajustar dropout dinámico\n",
        "for m in model.meta_net:\n",
        "    if isinstance(m, nn.Dropout):\n",
        "        m.p = drop_p\n",
        "for m in model.head:\n",
        "    if isinstance(m, nn.Dropout):\n",
        "        m.p = drop_p\n",
        "\n",
        "# 3. Congelar todo menos layer3+4\n",
        "for name, param in model.backbone.named_parameters():\n",
        "    param.requires_grad = False\n",
        "    if 'layer3' in name or 'layer4' in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# 4. Optimizer con tasas diferenciadas\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.backbone.layer3.parameters(), 'lr': lr_back3},\n",
        "    {'params': model.backbone.layer4.parameters(), 'lr': lr_back4},\n",
        "    {'params': model.meta_net.parameters(),           'lr': lr_meta},\n",
        "    {'params': model.head.parameters(),               'lr': lr_meta},\n",
        "])\n",
        "\n",
        "# 5. Escaler y loss\n",
        "scaler     = GradScaler(device_str)\n",
        "loss_fn    = nn.MSELoss()\n",
        "num_epochs = 30\n",
        "patience   = 7\n",
        "best_val   = float('inf')\n",
        "stale      = 0\n",
        "\n",
        "# 6. Loop completo\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for imgs, metas, labels in train_loader:\n",
        "        imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_str):\n",
        "            preds = model(imgs, metas).squeeze(1)\n",
        "            loss  = loss_fn(preds, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        train_losses.append(loss.item())\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_losses, preds, trues = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, metas, labels in val_loader:\n",
        "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "            with autocast(device_str):\n",
        "                out = model(imgs, metas).squeeze(1)\n",
        "                val_losses.append(loss_fn(out, labels).item())\n",
        "            preds.append(out.cpu())\n",
        "            trues.append(labels.cpu())\n",
        "    # Métricas\n",
        "    val_loss = sum(val_losses) / len(val_losses)\n",
        "    y_pred   = torch.cat(preds).numpy()\n",
        "    y_true   = torch.cat(trues).numpy()\n",
        "    val_mae  = mean_absolute_error(y_true, y_pred)\n",
        "    val_r2   = r2_score(y_true, y_pred)\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {np.mean(train_losses):.4f} | Val MAE: {val_mae:.4f} | Val R²: {val_r2:.4f}\")\n",
        "\n",
        "    # Early stopping simple\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        stale    = 0\n",
        "        torch.save(model.state_dict(), 'final_model.pt')\n",
        "    else:\n",
        "        stale += 1\n",
        "        if stale >= patience:\n",
        "            print(f\"No mejora en {patience} epochs. Deteniendo.\")\n",
        "            break\n",
        "\n",
        "print(\"Entrenamiento finalizado. Modelo guardado en final_model.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHIrGACy8x5J",
        "outputId": "7ad01c7f-6699-407e-e6b2-62061aaa5bb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 0.1075 | Val MAE: 0.1561 | Val R²: 0.3410\n",
            "Epoch 02 | Train Loss: 0.0440 | Val MAE: 0.0915 | Val R²: 0.7691\n",
            "Epoch 03 | Train Loss: 0.0408 | Val MAE: 0.1145 | Val R²: 0.6750\n",
            "Epoch 04 | Train Loss: 0.0379 | Val MAE: 0.1622 | Val R²: 0.2370\n",
            "Epoch 05 | Train Loss: 0.0257 | Val MAE: 0.0821 | Val R²: 0.8288\n",
            "Epoch 06 | Train Loss: 0.0237 | Val MAE: 0.0831 | Val R²: 0.8252\n",
            "Epoch 07 | Train Loss: 0.0235 | Val MAE: 0.0543 | Val R²: 0.9180\n",
            "Epoch 08 | Train Loss: 0.0204 | Val MAE: 0.0457 | Val R²: 0.9402\n",
            "Epoch 09 | Train Loss: 0.0203 | Val MAE: 0.0496 | Val R²: 0.9299\n",
            "Epoch 10 | Train Loss: 0.0197 | Val MAE: 0.0647 | Val R²: 0.8917\n",
            "Epoch 11 | Train Loss: 0.0172 | Val MAE: 0.0785 | Val R²: 0.8214\n",
            "Epoch 12 | Train Loss: 0.0176 | Val MAE: 0.0443 | Val R²: 0.9461\n",
            "Epoch 13 | Train Loss: 0.0148 | Val MAE: 0.0598 | Val R²: 0.9103\n",
            "Epoch 14 | Train Loss: 0.0157 | Val MAE: 0.0594 | Val R²: 0.9007\n",
            "Epoch 15 | Train Loss: 0.0136 | Val MAE: 0.0544 | Val R²: 0.9189\n",
            "No mejora en 7 epochs. Deteniendo.\n",
            "Entrenamiento finalizado. Modelo guardado en final_model.pt\n"
          ]
        }
      ]
    }
  ]
}